{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.039 Deep Learning Project\n",
    "\n",
    "Group Members:\n",
    "- Lee Chang Zheng\n",
    "- Lee Cheng Xin\n",
    "- Jason Peng Jing Ming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchaudio import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Audio samples into Spectrograms\n",
    "\n",
    "Before we can begin, we first have to convert the audio samples from .webm format into a standardised format. We will convert the files to .wav with single channel, a sample rate of 48000 Hz, and pad the audio files to 10 seconds long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert webm and ogg files to wav with single channel, sample rate of 48000 Hz, padded to 10 seconds long\n",
    "import subprocess\n",
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_audio(in_path, out_path):\n",
    "    if '.webm' in in_path:\n",
    "        subprocess.run([\"ffmpeg\", \"-i\", in_path, \"-y\", \"-ac\", \"1\", \"-ar\", \"48000\", out_path.replace('.webm', '.wav')])\n",
    "    elif '.ogg' in in_path:\n",
    "        subprocess.run([\"ffmpeg\", \"-i\", in_path, \"-y\", \"-ac\", \"1\", \"-ar\", \"48000\", out_path.replace('.ogg', '.wav')])\n",
    "\n",
    "def pad_trim_audio(in_path, out_path):\n",
    "    audio = AudioSegment.from_wav(in_path)\n",
    "    if len(audio) < 10000:\n",
    "        padding = AudioSegment.silent(duration=10000 - len(audio))\n",
    "        padded_audio = audio + padding\n",
    "        padded_audio.export(out_path, format='wav')\n",
    "    elif len(audio) > 10000:\n",
    "        trimmed_audio = audio[:10000]\n",
    "        trimmed_audio.export(out_path, format='wav')\n",
    "    \n",
    "# Note: These are commented out as the conversion has been done, it is simply for reference. You will need FFmpeg to run this.\n",
    "# for filename in os.listdir('./Data/Covid'):\n",
    "#     convert_audio(f'./Data/Covid/{filename}', f'./Converted/{filename}')\n",
    "# for filename in os.listdir('./Data/Healthy'):\n",
    "#     convert_audio(f'./Data/Healthy/{filename}', f'./Converted/{filename}')\n",
    "\n",
    "# # Padding/trimming the audio to 10 seconds long\n",
    "# for filename in os.listdir('./Converted'):\n",
    "#     pad_trim_audio(f'./Converted/{filename}', f'./Converted/{filename}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After standardizing the audio samples, we need to convert them into a Mel Spectrogram for the CNN model to process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the audio waveform into a spectrogram\n",
    "def audio_to_spec(audio, sample_rate, n_mels=128, n_fft=400, win_length=None, hop_length=None, top_db=80):\n",
    "    mel_spectrogram = transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_length,\n",
    "        hop_length=hop_length,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        n_mels=n_mels,\n",
    "    )\n",
    "    \n",
    "    melspec = mel_spectrogram(audio)\n",
    "    \n",
    "    transform = transforms.AmplitudeToDB(top_db=top_db)\n",
    "    final_spec = transform(melspec)\n",
    "    return final_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovidCoughDataset(Dataset):\n",
    "    def __init__(self, filename, datapath):\n",
    "        self.df = pd.read_excel(filename)\n",
    "        self.datapath = datapath\n",
    "        self.max_spec_length = 2400\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_file = self.datapath + self.df.iloc[index, 0] + '.wav'\n",
    "        status = 1 if self.df.iloc[index, 1] == 'COVID' else 0        \n",
    "        audio, sample_rate = torchaudio.load(audio_file)\n",
    "        spec = audio_to_spec(audio=audio, sample_rate=sample_rate)\n",
    "        \n",
    "        # Note: There might be some minor differences in the length of the audio clips, resulting in spectrograms of different\n",
    "        #       dimensions. We need to pad/trim the spectrograms to ensure consistency before we can feed into the model. \n",
    "        # Pad the shorter spectrograms to the maximum length\n",
    "        if spec.shape[2] < self.max_spec_length:\n",
    "            spec = F.pad(spec, (0, self.max_spec_length - spec.shape[2]), value=0)\n",
    "        # Trim the longer spectrograms to the maximum length\n",
    "        elif spec.shape[2] > self.max_spec_length:\n",
    "            spec = spec[:, :, :self.max_spec_length]\n",
    "        return spec, status\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2400])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "batch_size = 16\n",
    "\n",
    "dataset = CovidCoughDataset('./Data/Dataset.xlsx', './Converted/')\n",
    "print(dataset[0][0].shape)\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [0.8, 0.1, 0.1])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CovidClassifer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * (128//9) * (2400//9), 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(-1, 64 * (128//9) * (2400//9))\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, valid_dataloader, epochs = 10, lr = 0.001):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # Initialize epoch loss and accuracy\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_number, (inputs, labels) in enumerate(train_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            correct += (pred == labels).sum().item()\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{epochs}, Batch number: {batch_number}, Cumulated accuracy: {correct/total}')\n",
    "        \n",
    "        # Calculate epoch loss and accuracy\n",
    "        epoch_loss /= len(train_dataloader)\n",
    "        epoch_acc = correct/total\n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        print(f'--- Epoch {epoch+1}/{epochs}: Train loss: {epoch_loss:.4f}, Train accuracy: {epoch_acc:.4f}')\n",
    "    \n",
    "    return train_losses, train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\dlproject\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Batch number: 0, Cumulated accuracy: 0.75\n",
      "Epoch 1/3, Batch number: 1, Cumulated accuracy: 0.6875\n",
      "Epoch 1/3, Batch number: 2, Cumulated accuracy: 0.6458333333333334\n",
      "Epoch 1/3, Batch number: 3, Cumulated accuracy: 0.59375\n",
      "Epoch 1/3, Batch number: 4, Cumulated accuracy: 0.5625\n",
      "Epoch 1/3, Batch number: 5, Cumulated accuracy: 0.5208333333333334\n",
      "Epoch 1/3, Batch number: 6, Cumulated accuracy: 0.5267857142857143\n",
      "Epoch 1/3, Batch number: 7, Cumulated accuracy: 0.53125\n",
      "Epoch 1/3, Batch number: 8, Cumulated accuracy: 0.5277777777777778\n",
      "Epoch 1/3, Batch number: 9, Cumulated accuracy: 0.53125\n",
      "Epoch 1/3, Batch number: 10, Cumulated accuracy: 0.5284090909090909\n",
      "Epoch 1/3, Batch number: 11, Cumulated accuracy: 0.5260416666666666\n",
      "Epoch 1/3, Batch number: 12, Cumulated accuracy: 0.5240384615384616\n",
      "Epoch 1/3, Batch number: 13, Cumulated accuracy: 0.5178571428571429\n",
      "Epoch 1/3, Batch number: 14, Cumulated accuracy: 0.5333333333333333\n",
      "Epoch 1/3, Batch number: 15, Cumulated accuracy: 0.53515625\n",
      "Epoch 1/3, Batch number: 16, Cumulated accuracy: 0.5257352941176471\n",
      "Epoch 1/3, Batch number: 17, Cumulated accuracy: 0.5208333333333334\n",
      "Epoch 1/3, Batch number: 18, Cumulated accuracy: 0.5098684210526315\n",
      "Epoch 1/3, Batch number: 19, Cumulated accuracy: 0.50625\n",
      "Epoch 1/3, Batch number: 20, Cumulated accuracy: 0.5089285714285714\n",
      "Epoch 1/3, Batch number: 21, Cumulated accuracy: 0.5028409090909091\n",
      "Epoch 1/3, Batch number: 22, Cumulated accuracy: 0.49728260869565216\n",
      "Epoch 1/3, Batch number: 23, Cumulated accuracy: 0.4973958333333333\n",
      "Epoch 1/3, Batch number: 24, Cumulated accuracy: 0.4975\n",
      "Epoch 1/3, Batch number: 25, Cumulated accuracy: 0.4951923076923077\n",
      "Epoch 1/3, Batch number: 26, Cumulated accuracy: 0.4976851851851852\n",
      "Epoch 1/3, Batch number: 27, Cumulated accuracy: 0.49776785714285715\n",
      "Epoch 1/3, Batch number: 28, Cumulated accuracy: 0.4956896551724138\n",
      "Epoch 1/3, Batch number: 29, Cumulated accuracy: 0.4979166666666667\n",
      "Epoch 1/3, Batch number: 30, Cumulated accuracy: 0.49798387096774194\n",
      "Epoch 1/3, Batch number: 31, Cumulated accuracy: 0.5\n",
      "Epoch 1/3, Batch number: 32, Cumulated accuracy: 0.5018939393939394\n",
      "Epoch 1/3, Batch number: 33, Cumulated accuracy: 0.5\n",
      "Epoch 1/3, Batch number: 34, Cumulated accuracy: 0.5053571428571428\n",
      "Epoch 1/3, Batch number: 35, Cumulated accuracy: 0.5034722222222222\n",
      "Epoch 1/3, Batch number: 36, Cumulated accuracy: 0.5050675675675675\n",
      "Epoch 1/3, Batch number: 37, Cumulated accuracy: 0.5115131578947368\n",
      "Epoch 1/3, Batch number: 38, Cumulated accuracy: 0.5144230769230769\n",
      "Epoch 1/3, Batch number: 39, Cumulated accuracy: 0.515625\n",
      "Epoch 1/3, Batch number: 40, Cumulated accuracy: 0.510670731707317\n",
      "Epoch 1/3, Batch number: 41, Cumulated accuracy: 0.5133928571428571\n",
      "Epoch 1/3, Batch number: 42, Cumulated accuracy: 0.5130813953488372\n",
      "Epoch 1/3, Batch number: 43, Cumulated accuracy: 0.5127840909090909\n",
      "Epoch 1/3, Batch number: 44, Cumulated accuracy: 0.5138888888888888\n",
      "Epoch 1/3, Batch number: 45, Cumulated accuracy: 0.5067934782608695\n",
      "Epoch 1/3, Batch number: 46, Cumulated accuracy: 0.511968085106383\n",
      "Epoch 1/3, Batch number: 47, Cumulated accuracy: 0.515625\n",
      "Epoch 1/3, Batch number: 48, Cumulated accuracy: 0.5165816326530612\n",
      "Epoch 1/3, Batch number: 49, Cumulated accuracy: 0.5125\n",
      "Epoch 1/3, Batch number: 50, Cumulated accuracy: 0.5134803921568627\n",
      "Epoch 1/3, Batch number: 51, Cumulated accuracy: 0.5132211538461539\n",
      "Epoch 1/3, Batch number: 52, Cumulated accuracy: 0.5141509433962265\n",
      "Epoch 1/3, Batch number: 53, Cumulated accuracy: 0.5185185185185185\n",
      "Epoch 1/3, Batch number: 54, Cumulated accuracy: 0.5170454545454546\n",
      "Epoch 1/3, Batch number: 55, Cumulated accuracy: 0.515625\n",
      "Epoch 1/3, Batch number: 56, Cumulated accuracy: 0.5131578947368421\n",
      "Epoch 1/3, Batch number: 57, Cumulated accuracy: 0.5150862068965517\n",
      "Epoch 1/3, Batch number: 58, Cumulated accuracy: 0.5127118644067796\n",
      "Epoch 1/3, Batch number: 59, Cumulated accuracy: 0.5145833333333333\n",
      "Epoch 1/3, Batch number: 60, Cumulated accuracy: 0.5153688524590164\n",
      "Epoch 1/3, Batch number: 61, Cumulated accuracy: 0.5171370967741935\n",
      "Epoch 1/3, Batch number: 62, Cumulated accuracy: 0.5168650793650794\n",
      "Epoch 1/3, Batch number: 63, Cumulated accuracy: 0.515625\n",
      "Epoch 1/3, Batch number: 64, Cumulated accuracy: 0.5144230769230769\n",
      "Epoch 1/3, Batch number: 65, Cumulated accuracy: 0.5160984848484849\n",
      "Epoch 1/3, Batch number: 66, Cumulated accuracy: 0.519589552238806\n",
      "Epoch 1/3, Batch number: 67, Cumulated accuracy: 0.5202205882352942\n",
      "Epoch 1/3, Batch number: 68, Cumulated accuracy: 0.5217391304347826\n",
      "Epoch 1/3, Batch number: 69, Cumulated accuracy: 0.5205357142857143\n",
      "Epoch 1/3, Batch number: 70, Cumulated accuracy: 0.5202464788732394\n",
      "Epoch 1/3, Batch number: 71, Cumulated accuracy: 0.5182291666666666\n",
      "Epoch 1/3, Batch number: 72, Cumulated accuracy: 0.5171232876712328\n",
      "Epoch 1/3, Batch number: 73, Cumulated accuracy: 0.5177364864864865\n",
      "Epoch 1/3, Batch number: 74, Cumulated accuracy: 0.52\n",
      "Epoch 1/3, Batch number: 75, Cumulated accuracy: 0.5189144736842105\n",
      "Epoch 1/3, Batch number: 76, Cumulated accuracy: 0.5170454545454546\n",
      "Epoch 1/3, Batch number: 77, Cumulated accuracy: 0.5128205128205128\n",
      "Epoch 1/3, Batch number: 78, Cumulated accuracy: 0.5110759493670886\n",
      "Epoch 1/3, Batch number: 79, Cumulated accuracy: 0.51015625\n",
      "Epoch 1/3, Batch number: 80, Cumulated accuracy: 0.5131172839506173\n",
      "Epoch 1/3, Batch number: 81, Cumulated accuracy: 0.5114329268292683\n",
      "Epoch 1/3, Batch number: 82, Cumulated accuracy: 0.5117691723614275\n",
      "--- Epoch 1/3: Train loss: 90.4420, Train accuracy: 0.5118\n",
      "Epoch 2/3, Batch number: 0, Cumulated accuracy: 0.25\n",
      "Epoch 2/3, Batch number: 1, Cumulated accuracy: 0.40625\n",
      "Epoch 2/3, Batch number: 2, Cumulated accuracy: 0.5\n",
      "Epoch 2/3, Batch number: 3, Cumulated accuracy: 0.578125\n",
      "Epoch 2/3, Batch number: 4, Cumulated accuracy: 0.5625\n",
      "Epoch 2/3, Batch number: 5, Cumulated accuracy: 0.5729166666666666\n",
      "Epoch 2/3, Batch number: 6, Cumulated accuracy: 0.5535714285714286\n",
      "Epoch 2/3, Batch number: 7, Cumulated accuracy: 0.59375\n",
      "Epoch 2/3, Batch number: 8, Cumulated accuracy: 0.6041666666666666\n",
      "Epoch 2/3, Batch number: 9, Cumulated accuracy: 0.6125\n",
      "Epoch 2/3, Batch number: 10, Cumulated accuracy: 0.6193181818181818\n",
      "Epoch 2/3, Batch number: 11, Cumulated accuracy: 0.609375\n",
      "Epoch 2/3, Batch number: 12, Cumulated accuracy: 0.6153846153846154\n",
      "Epoch 2/3, Batch number: 13, Cumulated accuracy: 0.6205357142857143\n",
      "Epoch 2/3, Batch number: 14, Cumulated accuracy: 0.6166666666666667\n",
      "Epoch 2/3, Batch number: 15, Cumulated accuracy: 0.6171875\n",
      "Epoch 2/3, Batch number: 16, Cumulated accuracy: 0.6139705882352942\n",
      "Epoch 2/3, Batch number: 17, Cumulated accuracy: 0.6111111111111112\n",
      "Epoch 2/3, Batch number: 18, Cumulated accuracy: 0.6085526315789473\n",
      "Epoch 2/3, Batch number: 19, Cumulated accuracy: 0.6125\n",
      "Epoch 2/3, Batch number: 20, Cumulated accuracy: 0.6160714285714286\n",
      "Epoch 2/3, Batch number: 21, Cumulated accuracy: 0.6164772727272727\n",
      "Epoch 2/3, Batch number: 22, Cumulated accuracy: 0.6141304347826086\n",
      "Epoch 2/3, Batch number: 23, Cumulated accuracy: 0.6041666666666666\n",
      "Epoch 2/3, Batch number: 24, Cumulated accuracy: 0.605\n",
      "Epoch 2/3, Batch number: 25, Cumulated accuracy: 0.6105769230769231\n",
      "Epoch 2/3, Batch number: 26, Cumulated accuracy: 0.6087962962962963\n",
      "Epoch 2/3, Batch number: 27, Cumulated accuracy: 0.609375\n",
      "Epoch 2/3, Batch number: 28, Cumulated accuracy: 0.603448275862069\n",
      "Epoch 2/3, Batch number: 29, Cumulated accuracy: 0.59375\n",
      "Epoch 2/3, Batch number: 30, Cumulated accuracy: 0.5987903225806451\n",
      "Epoch 2/3, Batch number: 31, Cumulated accuracy: 0.60546875\n",
      "Epoch 2/3, Batch number: 32, Cumulated accuracy: 0.6041666666666666\n",
      "Epoch 2/3, Batch number: 33, Cumulated accuracy: 0.6029411764705882\n",
      "Epoch 2/3, Batch number: 34, Cumulated accuracy: 0.6035714285714285\n",
      "Epoch 2/3, Batch number: 35, Cumulated accuracy: 0.5989583333333334\n",
      "Epoch 2/3, Batch number: 36, Cumulated accuracy: 0.6013513513513513\n",
      "Epoch 2/3, Batch number: 37, Cumulated accuracy: 0.6036184210526315\n",
      "Epoch 2/3, Batch number: 38, Cumulated accuracy: 0.5993589743589743\n",
      "Epoch 2/3, Batch number: 39, Cumulated accuracy: 0.5984375\n",
      "Epoch 2/3, Batch number: 40, Cumulated accuracy: 0.5960365853658537\n",
      "Epoch 2/3, Batch number: 41, Cumulated accuracy: 0.5982142857142857\n",
      "Epoch 2/3, Batch number: 42, Cumulated accuracy: 0.5988372093023255\n",
      "Epoch 2/3, Batch number: 43, Cumulated accuracy: 0.6065340909090909\n",
      "Epoch 2/3, Batch number: 44, Cumulated accuracy: 0.6055555555555555\n",
      "Epoch 2/3, Batch number: 45, Cumulated accuracy: 0.6032608695652174\n",
      "Epoch 2/3, Batch number: 46, Cumulated accuracy: 0.6077127659574468\n",
      "Epoch 2/3, Batch number: 47, Cumulated accuracy: 0.61328125\n",
      "Epoch 2/3, Batch number: 48, Cumulated accuracy: 0.6147959183673469\n",
      "Epoch 2/3, Batch number: 49, Cumulated accuracy: 0.6125\n",
      "Epoch 2/3, Batch number: 50, Cumulated accuracy: 0.6127450980392157\n",
      "Epoch 2/3, Batch number: 51, Cumulated accuracy: 0.6117788461538461\n",
      "Epoch 2/3, Batch number: 52, Cumulated accuracy: 0.6108490566037735\n",
      "Epoch 2/3, Batch number: 53, Cumulated accuracy: 0.6099537037037037\n",
      "Epoch 2/3, Batch number: 54, Cumulated accuracy: 0.6090909090909091\n",
      "Epoch 2/3, Batch number: 55, Cumulated accuracy: 0.6138392857142857\n",
      "Epoch 2/3, Batch number: 56, Cumulated accuracy: 0.6140350877192983\n",
      "Epoch 2/3, Batch number: 57, Cumulated accuracy: 0.6174568965517241\n",
      "Epoch 2/3, Batch number: 58, Cumulated accuracy: 0.6228813559322034\n",
      "Epoch 2/3, Batch number: 59, Cumulated accuracy: 0.6229166666666667\n",
      "Epoch 2/3, Batch number: 60, Cumulated accuracy: 0.6239754098360656\n",
      "Epoch 2/3, Batch number: 61, Cumulated accuracy: 0.6229838709677419\n",
      "Epoch 2/3, Batch number: 62, Cumulated accuracy: 0.6220238095238095\n",
      "Epoch 2/3, Batch number: 63, Cumulated accuracy: 0.6181640625\n",
      "Epoch 2/3, Batch number: 64, Cumulated accuracy: 0.6173076923076923\n",
      "Epoch 2/3, Batch number: 65, Cumulated accuracy: 0.6183712121212122\n",
      "Epoch 2/3, Batch number: 66, Cumulated accuracy: 0.6175373134328358\n",
      "Epoch 2/3, Batch number: 67, Cumulated accuracy: 0.6148897058823529\n",
      "Epoch 2/3, Batch number: 68, Cumulated accuracy: 0.615036231884058\n",
      "Epoch 2/3, Batch number: 69, Cumulated accuracy: 0.6142857142857143\n",
      "Epoch 2/3, Batch number: 70, Cumulated accuracy: 0.6117957746478874\n",
      "Epoch 2/3, Batch number: 71, Cumulated accuracy: 0.6102430555555556\n",
      "Epoch 2/3, Batch number: 72, Cumulated accuracy: 0.6095890410958904\n",
      "Epoch 2/3, Batch number: 73, Cumulated accuracy: 0.6089527027027027\n",
      "Epoch 2/3, Batch number: 74, Cumulated accuracy: 0.6066666666666667\n",
      "Epoch 2/3, Batch number: 75, Cumulated accuracy: 0.6060855263157895\n",
      "Epoch 2/3, Batch number: 76, Cumulated accuracy: 0.6071428571428571\n",
      "Epoch 2/3, Batch number: 77, Cumulated accuracy: 0.6081730769230769\n",
      "Epoch 2/3, Batch number: 78, Cumulated accuracy: 0.6083860759493671\n",
      "Epoch 2/3, Batch number: 79, Cumulated accuracy: 0.61015625\n",
      "Epoch 2/3, Batch number: 80, Cumulated accuracy: 0.6087962962962963\n",
      "Epoch 2/3, Batch number: 81, Cumulated accuracy: 0.6105182926829268\n",
      "Epoch 2/3, Batch number: 82, Cumulated accuracy: 0.6112376613515565\n",
      "--- Epoch 2/3: Train loss: 6.6984, Train accuracy: 0.6112\n",
      "Epoch 3/3, Batch number: 0, Cumulated accuracy: 0.75\n",
      "Epoch 3/3, Batch number: 1, Cumulated accuracy: 0.71875\n",
      "Epoch 3/3, Batch number: 2, Cumulated accuracy: 0.7083333333333334\n",
      "Epoch 3/3, Batch number: 3, Cumulated accuracy: 0.65625\n",
      "Epoch 3/3, Batch number: 4, Cumulated accuracy: 0.6125\n",
      "Epoch 3/3, Batch number: 5, Cumulated accuracy: 0.65625\n",
      "Epoch 3/3, Batch number: 6, Cumulated accuracy: 0.6607142857142857\n",
      "Epoch 3/3, Batch number: 7, Cumulated accuracy: 0.671875\n",
      "Epoch 3/3, Batch number: 8, Cumulated accuracy: 0.6736111111111112\n",
      "Epoch 3/3, Batch number: 9, Cumulated accuracy: 0.66875\n",
      "Epoch 3/3, Batch number: 10, Cumulated accuracy: 0.6590909090909091\n",
      "Epoch 3/3, Batch number: 11, Cumulated accuracy: 0.671875\n",
      "Epoch 3/3, Batch number: 12, Cumulated accuracy: 0.6875\n",
      "Epoch 3/3, Batch number: 13, Cumulated accuracy: 0.6964285714285714\n",
      "Epoch 3/3, Batch number: 14, Cumulated accuracy: 0.7041666666666667\n",
      "Epoch 3/3, Batch number: 15, Cumulated accuracy: 0.70703125\n",
      "Epoch 3/3, Batch number: 16, Cumulated accuracy: 0.7058823529411765\n",
      "Epoch 3/3, Batch number: 17, Cumulated accuracy: 0.7083333333333334\n",
      "Epoch 3/3, Batch number: 18, Cumulated accuracy: 0.7105263157894737\n",
      "Epoch 3/3, Batch number: 19, Cumulated accuracy: 0.70625\n",
      "Epoch 3/3, Batch number: 20, Cumulated accuracy: 0.7113095238095238\n",
      "Epoch 3/3, Batch number: 21, Cumulated accuracy: 0.71875\n",
      "Epoch 3/3, Batch number: 22, Cumulated accuracy: 0.7282608695652174\n",
      "Epoch 3/3, Batch number: 23, Cumulated accuracy: 0.7317708333333334\n",
      "Epoch 3/3, Batch number: 24, Cumulated accuracy: 0.73\n",
      "Epoch 3/3, Batch number: 25, Cumulated accuracy: 0.7307692307692307\n",
      "Epoch 3/3, Batch number: 26, Cumulated accuracy: 0.7291666666666666\n",
      "Epoch 3/3, Batch number: 27, Cumulated accuracy: 0.7232142857142857\n",
      "Epoch 3/3, Batch number: 28, Cumulated accuracy: 0.7241379310344828\n",
      "Epoch 3/3, Batch number: 29, Cumulated accuracy: 0.725\n",
      "Epoch 3/3, Batch number: 30, Cumulated accuracy: 0.7278225806451613\n",
      "Epoch 3/3, Batch number: 31, Cumulated accuracy: 0.728515625\n",
      "Epoch 3/3, Batch number: 32, Cumulated accuracy: 0.7310606060606061\n",
      "Epoch 3/3, Batch number: 33, Cumulated accuracy: 0.7297794117647058\n",
      "Epoch 3/3, Batch number: 34, Cumulated accuracy: 0.7321428571428571\n",
      "Epoch 3/3, Batch number: 35, Cumulated accuracy: 0.734375\n",
      "Epoch 3/3, Batch number: 36, Cumulated accuracy: 0.731418918918919\n",
      "Epoch 3/3, Batch number: 37, Cumulated accuracy: 0.7286184210526315\n",
      "Epoch 3/3, Batch number: 38, Cumulated accuracy: 0.7291666666666666\n",
      "Epoch 3/3, Batch number: 39, Cumulated accuracy: 0.73125\n",
      "Epoch 3/3, Batch number: 40, Cumulated accuracy: 0.7362804878048781\n",
      "Epoch 3/3, Batch number: 41, Cumulated accuracy: 0.7410714285714286\n",
      "Epoch 3/3, Batch number: 42, Cumulated accuracy: 0.7398255813953488\n",
      "Epoch 3/3, Batch number: 43, Cumulated accuracy: 0.7400568181818182\n",
      "Epoch 3/3, Batch number: 44, Cumulated accuracy: 0.7388888888888889\n",
      "Epoch 3/3, Batch number: 45, Cumulated accuracy: 0.7364130434782609\n",
      "Epoch 3/3, Batch number: 46, Cumulated accuracy: 0.7353723404255319\n",
      "Epoch 3/3, Batch number: 47, Cumulated accuracy: 0.7356770833333334\n",
      "Epoch 3/3, Batch number: 48, Cumulated accuracy: 0.735969387755102\n",
      "Epoch 3/3, Batch number: 49, Cumulated accuracy: 0.74\n",
      "Epoch 3/3, Batch number: 50, Cumulated accuracy: 0.741421568627451\n",
      "Epoch 3/3, Batch number: 51, Cumulated accuracy: 0.7415865384615384\n",
      "Epoch 3/3, Batch number: 52, Cumulated accuracy: 0.7405660377358491\n",
      "Epoch 3/3, Batch number: 53, Cumulated accuracy: 0.7384259259259259\n",
      "Epoch 3/3, Batch number: 54, Cumulated accuracy: 0.7386363636363636\n",
      "Epoch 3/3, Batch number: 55, Cumulated accuracy: 0.7410714285714286\n",
      "Epoch 3/3, Batch number: 56, Cumulated accuracy: 0.743421052631579\n",
      "Epoch 3/3, Batch number: 57, Cumulated accuracy: 0.7456896551724138\n",
      "Epoch 3/3, Batch number: 58, Cumulated accuracy: 0.7457627118644068\n",
      "Epoch 3/3, Batch number: 59, Cumulated accuracy: 0.7479166666666667\n",
      "Epoch 3/3, Batch number: 60, Cumulated accuracy: 0.7489754098360656\n",
      "Epoch 3/3, Batch number: 61, Cumulated accuracy: 0.7479838709677419\n",
      "Epoch 3/3, Batch number: 62, Cumulated accuracy: 0.75\n",
      "Epoch 3/3, Batch number: 63, Cumulated accuracy: 0.751953125\n",
      "Epoch 3/3, Batch number: 64, Cumulated accuracy: 0.7519230769230769\n",
      "Epoch 3/3, Batch number: 65, Cumulated accuracy: 0.7462121212121212\n",
      "Epoch 3/3, Batch number: 66, Cumulated accuracy: 0.7490671641791045\n",
      "Epoch 3/3, Batch number: 67, Cumulated accuracy: 0.7481617647058824\n",
      "Epoch 3/3, Batch number: 68, Cumulated accuracy: 0.7463768115942029\n",
      "Epoch 3/3, Batch number: 69, Cumulated accuracy: 0.7455357142857143\n",
      "Epoch 3/3, Batch number: 70, Cumulated accuracy: 0.7464788732394366\n",
      "Epoch 3/3, Batch number: 71, Cumulated accuracy: 0.7456597222222222\n",
      "Epoch 3/3, Batch number: 72, Cumulated accuracy: 0.7457191780821918\n",
      "Epoch 3/3, Batch number: 73, Cumulated accuracy: 0.7466216216216216\n",
      "Epoch 3/3, Batch number: 74, Cumulated accuracy: 0.7458333333333333\n",
      "Epoch 3/3, Batch number: 75, Cumulated accuracy: 0.7425986842105263\n",
      "Epoch 3/3, Batch number: 76, Cumulated accuracy: 0.7410714285714286\n",
      "Epoch 3/3, Batch number: 77, Cumulated accuracy: 0.7419871794871795\n",
      "Epoch 3/3, Batch number: 78, Cumulated accuracy: 0.7365506329113924\n",
      "Epoch 3/3, Batch number: 79, Cumulated accuracy: 0.734375\n",
      "Epoch 3/3, Batch number: 80, Cumulated accuracy: 0.7345679012345679\n",
      "Epoch 3/3, Batch number: 81, Cumulated accuracy: 0.7324695121951219\n",
      "Epoch 3/3, Batch number: 82, Cumulated accuracy: 0.7304479878511769\n",
      "--- Epoch 3/3: Train loss: 3.5208, Train accuracy: 0.7304\n"
     ]
    }
   ],
   "source": [
    "model = CovidClassifer().to(device)\n",
    "\n",
    "train_losses, train_accuracies = train(model, train_dataloader, valid_dataloader, epochs = 3, lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
